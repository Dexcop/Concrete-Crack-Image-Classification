{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7c14534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.feature import hog\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e8d63f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = './dataset/'\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89742cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ORB\n",
    "MAX_FEATURES = 100  # Number of max keypoint that will try\n",
    "DESC_SIZE = 32      # ORB Descriptor Size (selalu 32 byte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3344170b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting file paths and labels\n",
      "Total images: 40000\n",
      "Training test size: 30000\n",
      "Testing test size: 10000\n"
     ]
    }
   ],
   "source": [
    "print('Getting file paths and labels')\n",
    "\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "positive_path = os.path.join(DATASET_PATH, 'Positive')\n",
    "negative_path = os.path.join(DATASET_PATH, 'Negative')\n",
    "\n",
    "for filename in os.listdir(positive_path):\n",
    "    image_paths.append(os.path.join(positive_path, filename))\n",
    "    labels.append(1)\n",
    "    \n",
    "for filename in os.listdir(negative_path):\n",
    "    image_paths.append(os.path.join(negative_path, filename))\n",
    "    labels.append(0)\n",
    "    \n",
    "image_paths = np.array(image_paths)\n",
    "labels = np.array(labels)\n",
    "\n",
    "X_train_paths, X_test_paths, y_train, y_test = train_test_split(\n",
    "    image_paths, labels, test_size=0.25, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "print(f'Total images: {len(image_paths)}')\n",
    "print(f'Training test size: {len(X_train_paths)}')\n",
    "print(f'Testing test size: {len(X_test_paths)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51cdb49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ini untuk HOG (Histogram of Oriented Gradients) Model => Global Feature Descriptor\n",
    "\n",
    "def feature_generator_hog(image_paths, labels, batch_size):\n",
    "    num_samples = len(image_paths)\n",
    "    \n",
    "    while True:\n",
    "        indices = np.arange(num_samples)\n",
    "\n",
    "        # Dishuffle biar gak terjadi data leakage\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        shuffled_paths = image_paths[indices]\n",
    "        shuffled_labels = labels[indices]\n",
    "        \n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            batch_paths = shuffled_paths[i:i+batch_size]\n",
    "            batch_labels = shuffled_labels[i:i+batch_size]\n",
    "            \n",
    "            batch_features = []\n",
    "            \n",
    "            for img_path in batch_paths:\n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT)) # Ini wajib karena HOG menghasilkan vektor fitur dengan panjang yang bergantung pada ukuran gambar. Semua gambar harus berukuran sama agar fiturnya bisa dibandingkan.\n",
    "                \n",
    "                gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                features = hog( gray_image, \n",
    "                                # Fungsi dari pixel per cell karena di dalam setiap sel, HOG menghitung \"arah\" gradien (perubahan dari gelap ke terang) dan membuat histogram kecil. \n",
    "                                # Intinya, ini menangkap struktur lokal seperti tepi atau sudut dalam area 16x16 piksel.\n",
    "\n",
    "                                pixels_per_cell=(16, 16), \n",
    "                                # Blok digunakan untuk normalisasi kontras. Ini membuat fitur HOG lebih tahan terhadap perubahan pencahayaan.\n",
    "                                # Seperti contohnya retakan beton di bawah sinar matahari terik dan di bawah bayangan akan memiliki fitur HOG yang mirip karena adanya normalisasi ini.                  \n",
    "                               \n",
    "                               cells_per_block=(2, 2),\n",
    "                               visualize=False,\n",
    "                               block_norm='L2-Hys',\n",
    "                               # Metode yang digunakan untuk normalisasi di dalam blok. 'L2-Hys' (L2-Hysteresis) adalah metode standar yang sangat populer dan bekerja dengan baik. \n",
    "                               # Ia melakukan normalisasi L2, membatasi nilai maksimum (clipping), lalu menormalisasi lagi.\n",
    "                               \n",
    "                               feature_vector=True\n",
    "                               # Ini memastikan output dari fungsi hog adalah satu vektor 1D yang datar (flattened). \n",
    "                               # Jika False, outputnya akan berupa array multi-dimensi. \n",
    "                               # Untuk dimasukkan ke model klasifikasi standar (seperti SVM atau Random Forest), kita memerlukan vektor 1D.\n",
    "                               ) \n",
    "                \n",
    "                batch_features.append(features)\n",
    "            \n",
    "            yield np.array(batch_features), np.array(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84ff3c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ini untuk ORB (Oriented FAST and Rotated BRIEF) Model => Local Feature Descriptor\n",
    "\n",
    "\n",
    "def feature_generator_orb(image_paths, labels, batch_size):\n",
    "    num_samples = len(image_paths)\n",
    "    \n",
    "    orb = cv2.ORB_create(nfeatures=MAX_FEATURES)\n",
    "    # Ini memberitahu ORB untuk mencari maksimal MAX_FEATURES (misalnya 100) titik paling \"menarik\" di gambar. \n",
    "    # Ini adalah langkah pertama untuk memastikan output kita konsisten.\n",
    "    \n",
    "    while True:\n",
    "        indices = np.arange(num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        shuffled_paths = image_paths[indices]\n",
    "        shuffled_labels = labels[indices]\n",
    "        \n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            batch_paths = shuffled_paths[i:i+batch_size]\n",
    "            batch_labels = shuffled_labels[i:i+batch_size]\n",
    "            \n",
    "            batch_features = []\n",
    "            \n",
    "            for img_path in batch_paths:\n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "                \n",
    "                gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                kps, des = orb.detectAndCompute(gray_image, None)\n",
    "                # kps => keypoints\n",
    "                # des => descriptor\n",
    "                \n",
    "                flat_features = np.zeros(MAX_FEATURES * DESC_SIZE, dtype=np.float32)\n",
    "                # awal kita buat semuanya itu menjadi [0,0]\n",
    "                if des is not None:\n",
    "                    num_descriptors = min(len(des), MAX_FEATURES) # capping => tidak ambil lebih dari batas feature jumlah maksimal\n",
    "                    flat_features[:num_descriptors * DESC_SIZE] = des[:num_descriptors].ravel()\n",
    "                    # des[:num_descriptors] mengambil semua deskriptor yang valid (maksimal 100).\n",
    "\n",
    "                    # .ravel() \"meratakan\" array (100, 32) menjadi satu baris panjang (3200,).\n",
    "\n",
    "                    # flat_features[...] = ... menyalin nilai-nilai ini ke dalam \"wadah\" nol yang kita siapkan.\n",
    "                flat_features /= (np.linalg.norm(flat_features) + 1e-6)\n",
    "                # flat_features /= ...: Vektor yang sudah jadi kemudian dinormalisasi. \n",
    "                # Ini membuat fitur lebih tahan terhadap perbedaan pencahayaan antar gambar.\n",
    "                \n",
    "                batch_features.append(flat_features)\n",
    "            \n",
    "            yield np.array(batch_features), np.array(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7a8e27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification of HOG Model\n",
      "fetching one batch of feature vectors to test\n",
      "pipeline complete, ready for training\n",
      "shape of one batch of features: (32, 6084)\n",
      "shape of one batch of labels: (32,)\n",
      "example feature vector (first image in batch:\n",
      " [0.15661954 0.03150942 0.18533269 ... 0.09731695 0.18364888 0.10774113])\n"
     ]
    }
   ],
   "source": [
    "# Verification\n",
    "print('Verification of HOG Model')\n",
    "train_gen_hog = feature_generator_hog(X_train_paths, y_train, BATCH_SIZE)\n",
    "\n",
    "print('fetching one batch of feature vectors to test')\n",
    "sample_batch_features_hog, sample_batch_labels_hog = next(train_gen_hog) \n",
    "\n",
    "print('pipeline complete, ready for training')\n",
    "print(f'shape of one batch of features: {sample_batch_features_hog.shape}') # 32 per batch and 10 length\n",
    "print(f'shape of one batch of labels: {sample_batch_labels_hog.shape}')  # 32 per batch\n",
    "print(f'example feature vector (first image in batch:\\n {sample_batch_features_hog[0]})') # 10 arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44dc3bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification of ORB Model\n",
      "fetching one batch of feature vectors to test\n",
      "pipeline complete, ready for training\n",
      "shape of one batch of features: (32, 3200)\n",
      "shape of one batch of labels: (32,)\n",
      "example feature vector (first image in batch:\n",
      " [0.00590111 0.02095494 0.02842165 ... 0.         0.         0.        ])\n"
     ]
    }
   ],
   "source": [
    "# Verification\n",
    "print('Verification of ORB Model')\n",
    "train_gen_orb = feature_generator_orb(X_train_paths, y_train, BATCH_SIZE)\n",
    "\n",
    "print('fetching one batch of feature vectors to test')\n",
    "sample_batch_features_orb, sample_batch_labels_orb = next(train_gen_orb) \n",
    "\n",
    "print('pipeline complete, ready for training')\n",
    "print(f'shape of one batch of features: {sample_batch_features_orb.shape}') # 32 per batch and 10 length\n",
    "print(f'shape of one batch of labels: {sample_batch_labels_orb.shape}')  # 32 per batch\n",
    "print(f'example feature vector (first image in batch:\\n {sample_batch_features_orb[0]})') # 10 arrays"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Computer Vision)",
   "language": "python",
   "name": "comvis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
