{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7c14534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.feature import local_binary_pattern\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e8d63f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = './dataset/'\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3344170b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting file paths and labels\n",
      "Training test size: 30000\n",
      "Testing test size: 10000\n"
     ]
    }
   ],
   "source": [
    "print('Getting file paths and labels')\n",
    "\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "positive_path = os.path.join(DATASET_PATH, 'Positive')\n",
    "negative_path = os.path.join(DATASET_PATH, 'Negative')\n",
    "\n",
    "for filename in os.listdir(positive_path):\n",
    "    image_paths.append(os.path.join(positive_path, filename))\n",
    "    labels.append(1)\n",
    "    \n",
    "for filename in os.listdir(negative_path):\n",
    "    image_paths.append(os.path.join(negative_path, filename))\n",
    "    labels.append(0)\n",
    "    \n",
    "image_paths = np.array(image_paths)\n",
    "labels = np.array(labels)\n",
    "\n",
    "X_train_paths, X_test_paths, y_train, y_test = train_test_split(\n",
    "    image_paths, labels, test_size=0.25, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "print(f'Training test size: {len(X_train_paths)}')\n",
    "print(f'Testing test size: {len(X_test_paths)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a608f3c7",
   "metadata": {},
   "source": [
    "# Getting the best descriptor and detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d7322a",
   "metadata": {},
   "source": [
    "## just detector: using lbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51cdb49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_generator_lbp(image_paths, labels, batch_size):\n",
    "    num_samples = len(image_paths)\n",
    "    \n",
    "    while True:\n",
    "        indices = np.arange(num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        shuffled_paths = image_paths[indices]\n",
    "        shuffled_labels = labels[indices]\n",
    "        \n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            batch_paths = shuffled_paths[i:i+batch_size]\n",
    "            batch_labels = shuffled_labels[i:i+batch_size]\n",
    "            \n",
    "            batch_features = []\n",
    "            \n",
    "            for img_path in tqdm(batch_paths, desc='Batch Progress'):\n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "                \n",
    "                gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                gray_image_eq = cv2.equalizeHist(gray_image)\n",
    "                \n",
    "                lbp = local_binary_pattern(gray_image_eq, P=8, R=1, method='uniform')\n",
    "                \n",
    "                (hist, _) = np.histogram(lbp.ravel(), bins = np.arange(0, 11), range=(0, 10))\n",
    "                \n",
    "                hist = hist.astype('float')\n",
    "                \n",
    "                hist /= (hist.sum() + 1e-6)\n",
    "                \n",
    "                batch_features.append(hist)\n",
    "            \n",
    "            yield np.array(batch_features), np.array(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7a8e27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching one batch of feature vectors to test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Progress: 100%|██████████| 32/32 [00:00<00:00, 237.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline complete, ready for training\n",
      "shape of one batch of features: (32, 10)\n",
      "shape of one batch of labels: (32,)\n",
      "example feature vector (first image in batch:\n",
      " [0.02192283 0.06905692 0.04284917 0.16414222 0.16501913 0.19557159\n",
      " 0.11202567 0.06008849 0.07423868 0.0950853 ])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Verification\n",
    "train_gen_lbp = feature_generator_lbp(X_train_paths, y_train, BATCH_SIZE)\n",
    "\n",
    "print('fetching one batch of feature vectors to test')\n",
    "sample_batch_features, sample_batch_labels = next(train_gen_lbp) \n",
    "\n",
    "print('pipeline complete, ready for training')\n",
    "print(f'shape of one batch of features: {sample_batch_features.shape}') # 32 per batch and 10 length\n",
    "print(f'shape of one batch of labels: {sample_batch_labels.shape}')  # 32 per batch\n",
    "print(f'example feature vector (first image in batch:\\n {sample_batch_features[0]})') # 10 arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98d77a3",
   "metadata": {},
   "source": [
    "## detector with descriptor (fast + brief) - not worth exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3905e339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_generator_fast(image_paths, labels, batch_size):\n",
    "    print(\"--- RUNNING THE NEW, CORRECTED FAST GENERATOR V2 ---\")\n",
    "    fast = cv2.FastFeatureDetector_create(nonmaxSuppression=False)\n",
    "    fast.setThreshold(5)\n",
    "    brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "    \n",
    "    num_samples = len(image_paths)\n",
    "    \n",
    "    while True:\n",
    "        indices = np.arange(num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        shuffled_paths = image_paths[indices]\n",
    "        shuffled_labels = labels[indices]\n",
    "        \n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            batch_paths = shuffled_paths[i:i + batch_size]\n",
    "            batch_labels = shuffled_labels[i:i + batch_size]\n",
    "            \n",
    "            batch_features = []\n",
    "            \n",
    "            print(f'processing batch at index: {i}')\n",
    "            for img_path in tqdm(batch_paths, desc='Batch Progress'):\n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "                \n",
    "                gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                keypoints = fast.detect(gray_image, None)\n",
    "                \n",
    "                keypoints, descriptors = brief.compute(gray_image, keypoints)\n",
    "                \n",
    "                if descriptors is not None:\n",
    "                    feature_vector = np.mean(descriptors, axis=0)\n",
    "                else:\n",
    "                    feature_vector = np.zeros(32)\n",
    "                \n",
    "                batch_features.append(feature_vector)\n",
    "            \n",
    "            yield np.array(batch_features), np.array(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "283efb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching one batch of feature vectors to test\n",
      "--- RUNNING THE NEW, CORRECTED FAST GENERATOR V2 ---\n",
      "processing batch at index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Progress: 100%|██████████| 32/32 [00:00<00:00, 457.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline complete, ready for training\n",
      "shape of one batch of features: (32, 32)\n",
      "shape of one batch of labels: (32,)\n",
      "example feature vector (first image in batch:\n",
      " [139.65625  122.25     129.671875 131.75     143.34375  172.453125\n",
      " 124.4375   140.40625  185.9375   129.828125 156.015625 122.\n",
      "  73.8125    82.4375   136.890625 174.171875 158.296875 122.3125\n",
      " 130.953125 146.265625 104.421875 105.78125  152.6875   160.1875\n",
      " 127.703125 160.421875 126.640625 162.703125 151.46875  181.765625\n",
      " 123.4375   103.625   ])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Verification\n",
    "train_gen_fast = feature_generator_fast(X_train_paths, y_train, BATCH_SIZE)\n",
    "\n",
    "print('fetching one batch of feature vectors to test')\n",
    "sample_fast_batch_features, sample_fast_batch_labels = next(train_gen_fast) \n",
    "\n",
    "print('pipeline complete, ready for training')\n",
    "print(f'shape of one batch of features: {sample_fast_batch_features.shape}') # 32 per batch and 10 length\n",
    "print(f'shape of one batch of labels: {sample_fast_batch_labels.shape}')  # 32 per batch\n",
    "print(f'example feature vector (first image in batch:\\n {sample_fast_batch_features[0]})') # 10 arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6fc714",
   "metadata": {},
   "source": [
    "### fast is unreasonably fast, since a detector + descriptor combo usually will take a while\n",
    "so an isolated evaluation will be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6665b90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analyzing Cracked Images ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cracked: 100%|██████████| 10000/10000 [01:02<00:00, 159.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyzing Uncracked Images ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uncracked: 100%|██████████| 10000/10000 [00:44<00:00, 224.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- FINAL DIAGNOSTIC REPORT ---\n",
      "Average descriptors for CRACKED images: 3583.86\n",
      "Average descriptors for UNCRACKED images: 2135.19\n",
      "\n",
      "Your 'hero' image had 1375 descriptors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZE = 10000 \n",
    "\n",
    "fast = cv2.FastFeatureDetector_create(threshold=5, nonmaxSuppression=False)\n",
    "brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "\n",
    "def get_descriptor_count(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    keypoints_found = fast.detect(gray, None)\n",
    "    keypoints_kept, descriptors = brief.compute(gray, keypoints_found)\n",
    "    \n",
    "    return len(descriptors) if descriptors is not None else 0\n",
    "\n",
    "print(\"--- Analyzing Cracked Images ---\")\n",
    "positive_path = os.path.join(DATASET_PATH, 'Positive')\n",
    "positive_files = [os.path.join(positive_path, fname) for fname in os.listdir(positive_path)[:SAMPLE_SIZE]]\n",
    "positive_counts = [get_descriptor_count(path) for path in tqdm(positive_files, desc=\"Cracked\")]\n",
    "\n",
    "print(\"\\n--- Analyzing Uncracked Images ---\")\n",
    "negative_path = os.path.join(DATASET_PATH, 'Negative')\n",
    "negative_files = [os.path.join(negative_path, fname) for fname in os.listdir(negative_path)[:SAMPLE_SIZE]]\n",
    "negative_counts = [get_descriptor_count(path) for path in tqdm(negative_files, desc=\"Uncracked\")]\n",
    "\n",
    "print(\"\\n\\n--- FINAL DIAGNOSTIC REPORT ---\")\n",
    "print(f\"Average descriptors for CRACKED images: {np.mean(positive_counts):.2f}\")\n",
    "print(f\"Average descriptors for UNCRACKED images: {np.mean(negative_counts):.2f}\")\n",
    "print(f\"\\nYour 'hero' image had {positive_counts[0]} descriptors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62121be",
   "metadata": {},
   "source": [
    "--- Analyzing Cracked Images ---\n",
    "\n",
    "Cracked: 100%|██████████| 10000/10000 [01:02<00:00, 159.63it/s]\n",
    "\n",
    "--- Analyzing Uncracked Images ---\n",
    "\n",
    "Uncracked: 100%|██████████| 10000/10000 [00:44<00:00, 224.80it/s]\n",
    "\n",
    "\n",
    "--- FINAL DIAGNOSTIC REPORT ---\n",
    "\n",
    "Average descriptors for CRACKED images: 3583.86\n",
    "\n",
    "Average descriptors for UNCRACKED images: 2135.19\n",
    "\n",
    "Your 'hero' image had 1375 descriptors.\n",
    "\n",
    "\n",
    "very bad result, the uncracked image has so much descriptors, this shows that fast and brief is a bad combo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4762957",
   "metadata": {},
   "source": [
    "## orb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7370b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8968f406",
   "metadata": {},
   "source": [
    "## akaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3127e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
